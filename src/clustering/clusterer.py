import streamlit as st
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import OneHotEncoder
import os

# Directory where Parquet files are saved
PARQUET_DIR = os.path.join("data", "processed")

def perform_clustering(df, n_clusters):
    """Performs K-Means clustering on the dataset."""
    if df.empty:
        return None, None

    # Feature Engineering: One-hot encode the combined_text
    enc = OneHotEncoder(handle_unknown="ignore")
    X = enc.fit_transform(df[['combined_text']]).toarray()

    # Apply K-Means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df["cluster"] = kmeans.fit_predict(X)

    return df, kmeans

def app():
    st.title("Clustering")
    st.write("Suggests clusters to facilitate classification.")

    st.sidebar.title("Settings")

    # List all .parquet files in the data/processed directory
    if not os.path.exists(PARQUET_DIR):
        st.error(f"Directory '{PARQUET_DIR}' not found. Generate embeddings first.")
        return

    parquet_files = [f for f in os.listdir(PARQUET_DIR) if f.endswith(".parquet")]
    if not parquet_files:
        st.error(f"No Parquet files found in '{PARQUET_DIR}'. Generate embeddings first.")
        return

    # Let the user select a Parquet file
    selected_parquet = st.sidebar.selectbox(
        "Select a Parquet file to cluster",
        parquet_files,
        help="Choose a Parquet file generated by the Datasource app."
    )

    # Construct the full path to the selected Parquet file
    parquet_file = os.path.join(PARQUET_DIR, selected_parquet)

    n_similares = st.sidebar.slider("Number of Similar Elements", 1, 30, 10)
    n_clusters = st.sidebar.slider("Number of Clusters", 2, 50, 10)
    include_labeled = st.sidebar.checkbox(
        "Include Items with Labels",
        value=False,
        help="If checked, items with existing labels will be included in the labeling interface."
    )
    submit_button = st.sidebar.button("Submit")

    # Load DataFrame from the selected Parquet file into session state if not already loaded
    if "df" not in st.session_state:
        if not os.path.exists(parquet_file):
            st.error(f"File '{parquet_file}' not found. Generate the embeddings first.")
            return
        st.session_state.df = pd.read_parquet(parquet_file)

    # Perform clustering when "Submit" is clicked
    if submit_button:
        df = st.session_state.df.copy()
        df, kmeans = perform_clustering(df, n_clusters)

        if df is not None:
            st.session_state.df = df
            # Initialize cluster index if not already set
            if 'cluster' not in st.session_state:
                st.session_state.cluster = 0
            # Display cluster distribution
            st.write("### Cluster Distribution")
            cluster_counts = df['cluster'].value_counts().sort_index().to_dict()
            st.write({f"Cluster {k+1}": v for k, v in cluster_counts.items()})
            # Save the clustered DataFrame to the .parquet file
            try:
                st.session_state.df.to_parquet(parquet_file, index=False)
                st.success("Clustering completed and file updated successfully!")
            except Exception as e:
                st.error(f"Error saving file: {e}")
                return

    # If clustering has been performed, show the labeling interface
    if "cluster" in st.session_state.df.columns:
        df = st.session_state.df
        # Get distinct labels from the DataFrame
        distinct_labels = [x for x in df['label'].unique() if pd.notnull(x) and x.strip() != ""]
        distinct_labels.sort()

        # Replace NaN or empty labels with an empty string for consistency
        df['label'] = df['label'].fillna("")

        # Conditionally filter the DataFrame based on the toggle
        if not include_labeled:
            df_filtered = df[df['label'] == ""]
        else:
            df_filtered = df  # Include all items, labeled or not

        # Get the current cluster index
        if 'cluster' not in st.session_state:
            st.session_state.cluster = 0
        cluster = st.session_state.cluster

        # Display clustering parameters
        st.header("Parameters")
        st.write(f"Displaying up to {n_similares} similar elements")
        st.write(f"Cluster: {cluster+1} of {n_clusters}")
        labels_count = df_filtered.shape[0]
        empty_labels_count = df_filtered['label'].eq("").sum()
        st.write(f"Number of elements without a label: {empty_labels_count}/{labels_count}")

        # Navigation buttons for clusters
        next_back_cols = st.columns([1, 1, 2])
        with next_back_cols[0]:
            if st.button("BACK"):
                st.session_state.cluster = (cluster - 1) % n_clusters
        with next_back_cols[1]:
            if st.button("NEXT"):
                st.session_state.cluster = (cluster + 1) % n_clusters

        # Update cluster index after button clicks
        cluster = st.session_state.cluster

        # Select similar documents based on the toggle
        if not include_labeled:
            similar_docs = df_filtered[(df_filtered['cluster'] == cluster) & (df_filtered['label'] == "")]
        else:
            similar_docs = df_filtered[df_filtered['cluster'] == cluster]

        # Warn if the cluster is empty or has fewer documents than requested
        if similar_docs.empty:
            st.warning(f"Cluster {cluster+1} is empty. Try navigating to another cluster or adjust the number of clusters.")
        elif len(similar_docs) < n_similares:
            st.info(f"Cluster {cluster+1} has only {len(similar_docs)} documents, fewer than the requested {n_similares}.")

        similar_docs = similar_docs.head(n_similares)

        # Labeling interface
        st.header("Selection of Cluster Labels")

        # Use distinct labels from the DataFrame
        existing_labels = distinct_labels if distinct_labels else []

        label_cols = st.columns([2, 3, 2])
        with label_cols[0]:
            selected_label = st.selectbox("Select a label", existing_labels) if existing_labels else st.text_input("Enter a label")
        with label_cols[1]:
            new_label = st.text_input("Add New Label")
        with label_cols[2]:
            if st.button("Add Label"):
                if new_label and new_label not in existing_labels:
                    existing_labels.append(new_label)
                    st.success(f"Label '{new_label}' added successfully.")

        st.header("Similar Elements in the Cluster")

        selected_similars = []
        for idx, row in similar_docs.iterrows():
            # Display the id_doc, combined_text, and label (if available)
            label_display = f" (Label: {row['label']})" if row['label'] else ""
            display_text = f"[{row['id_doc']}] - {row['combined_text'][0:1000]}{label_display}"
            if st.checkbox(display_text, key=idx, value=True):
                selected_similars.append(idx)

        if st.button("LABEL"):
            for idx in selected_similars:
                st.session_state.df.at[idx, 'label'] = selected_label if existing_labels else new_label

            try:
                st.session_state.df.to_parquet(parquet_file, index=False)
                st.success("Elements labeled successfully and file updated!")
            except Exception as e:
                st.error(f"Error saving file: {e}")

if __name__ == "__main__":
    app()